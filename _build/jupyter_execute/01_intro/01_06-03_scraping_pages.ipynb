{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suited-breathing",
   "metadata": {},
   "source": [
    "# Scraping Ιστοσελίδων με τις Requests και BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-netherlands",
   "metadata": {},
   "source": [
    "## Εισαγωγή"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-locking",
   "metadata": {},
   "source": [
    "Στην προηγούμενη ενότητα, μάθαμε για τα βασικά της HTML και τη βιβλιοθήκη BeautifulSoup. Δεν εργαζόμασταν, ωστόσο, με δεδομένα που βρίσκονται στον ιστό, αλλά η HTML μας ήταν αποθηκευμένη τοπικά. Σε αυτή την ενότητα, θα μάθουμε πώς να κάνουμε κλήσεις σε έναν απομακρυσμένο διακομιστή με τη βιβλιοθήκη requests και στη συνέχεια να αναλύουμε αυτά τα δεδομένα με την BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-ethiopia",
   "metadata": {},
   "source": [
    "## Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-remove",
   "metadata": {},
   "source": [
    "Η βιβλιοθήκη **requests** μας επιτρέπει να στείλουμε ένα σήμα μέσω Python σε έναν διακομιστή. Ένας καλός τρόπος να σκεφτείτε τις requests είναι ως ένας αόρατος browser που ανοίγει στο παρασκήνιο του υπολογιστή σας. Οι Requests κάνουν ακριβώς το πράγμα που κάνει ο browser σας. Στέλνουν ένα σήμα μέσω του διαδικτύου για να συνδεθούν σε μια συγκεκριμένη διεύθυνση διακομιστή. Ενώ όλοι οι διακομιστές έχουν μια μοναδική διεύθυνση IP, συχνά το διαδίκτυο συνδέει μια συγκεκριμένη και μοναδική διεύθυνση που μπορεί να χρησιμοποιηθεί ως τρόπος σύνδεσης σε έναν διακομιστή χωρίς να χρειάζεται να πληκτρολογήσετε μια διεύθυνση IP. Σε αντίθεση με τον browser σας, ωστόσο, οι requests δεν εμφανίζουν τα αποτελέσματα για να τα δείτε. Αντίθετα, λαμβάνουν το σήμα επιστροφής και απλώς αποθηκεύουν τα δεδομένα HTML στη μνήμη.\n",
    "\n",
    "Για να αρχίσουμε να μαθαίνουμε πώς λειτουργούν οι requests, ας εισάγουμε πρώτα τη βιβλιοθήκη requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beginning-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7a346-988b-43e1-b9ec-ae5d6dea588c",
   "metadata": {},
   "source": [
    "Τώρα που έχουμε εισάγει τις requests, ας προχωρήσουμε και ας δημιουργήσουμε ένα string object που θα είναι ο ιστότοπος που θέλουμε να κάνουμε scrape. Πάντα ονομάζω αυτή τη συμβολοσειρά \"url\" στον κώδικά μου."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "three-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_French_monarchs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef3e8b3-eb1d-40d4-b519-918aac67bee2",
   "metadata": {},
   "source": [
    "Εξαιρετικά! Τώρα μπορούμε να χρησιμοποιήσουμε τη βιβλιοθήκη requests για να κάνουμε μια κλήση σε αυτή τη συγκεκριμένη σελίδα. Θα το κάνουμε αυτό μέσω της συνάρτησης get στη βιβλιοθήκη requests. Η συνάρτηση get έχει ένα υποχρεωτικό όρισμα: τον ιστότοπο που θέλετε να ζητήσετε. Στην περίπτωσή μας, αυτή θα είναι η συμβολοσειρά \"url\" μας."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "invisible-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd78656-86df-4f8a-bc95-ed6a2a3d4f3c",
   "metadata": {},
   "source": [
    "Τώρα που έχουμε δημιουργήσει ένα request object, ας ρίξουμε μια ματιά στο πώς φαίνεται αυτό."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a4835e-b418-4718-936a-e6e7f497788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print (s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f20ef-0204-46e7-8e72-f3be096282b3",
   "metadata": {},
   "source": [
    "Στην επιφάνεια, αυτό μοιάζει σαν να μπορεί να αποτύχαμε. Τι είναι αυτό το περίεργο \"response 200\" και τι σημαίνει; Αυτή η συγκεκριμένη απάντηση σημαίνει ότι η προσπάθειά μας να συνδεθούμε σε έναν διακομιστή ήταν επιτυχής. Υπάρχουν πολλοί τύποι απαντήσεων, αλλά το 200 είναι αυτό που θέλουμε να δούμε. Εάν δείτε ποτέ μια απάντηση που δεν είναι 200, μπορείτε να αναζητήσετε στο Google τη συγκεκριμένη απάντηση διακομιστή και θα μάθετε τι συμβαίνει. Μερικές φορές, μια απάντηση υποδεικνύει ότι το αίτημά σας μπλοκαρίστηκε. Αυτό μπορεί να οφείλεται στο ότι ο ιστότοπος έχει μέτρα κατά του web scraping. Σε άλλες περιπτώσεις, η σελίδα μπορεί να είναι προστατευμένη, πράγμα που σημαίνει ότι βρίσκεται πίσω από ένα login. Υπάρχουν πάρα πολλά πιθανά σφάλματα που μπορεί να προκύψουν που δεν μπορώ να τα περιγράψω όλα σε αυτό το βασικό εισαγωγικό κεφάλαιο. Ωστόσο, θα σας δώσω μια λύση σε ένα πολύ κοινό πρόβλημα που μπορεί να σας επιτρέψει να ξεπεράσετε μια κοινή απάντηση 403. Για αυτή τη λύση, δείτε την τελευταία ενότητα αυτού του κεφαλαίου."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a79a16-0f26-4a71-b1f0-839fa94dc46d",
   "metadata": {},
   "source": [
    "## BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9253b7c0-f6fa-4b94-9a2e-6794e8bdef83",
   "metadata": {},
   "source": [
    "Τώρα που μάθαμε πώς να κάνουμε μια κλήση σε έναν διακομιστή και αποθηκεύσαμε την απάντηση (την HTML) στη μνήμη, χρειαζόμαστε έναν τρόπο να αναλύσουμε αυτά τα δεδομένα. Θαμμένο μέσα στο s request object είναι το περιεχόμενο HTML. Μπορούμε να έχουμε πρόσβαση σε αυτά τα δεδομένα προσπελαύνοντας τη μέθοδο content της κλάσης response object. Ας το κάνουμε αυτό και ας ελέγξουμε τους πρώτους 100 χαρακτήρες."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee722a71-2b17-4cb0-b635-81df38b69556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title'\n"
     ]
    }
   ],
   "source": [
    "print (s.content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7653fd94-2dbe-46b4-ad51-bb1e1603cde9",
   "metadata": {},
   "source": [
    "Παρατηρήστε ότι αυτά τα δεδομένα είναι HTML. Σε αυτό το στάδιο, ωστόσο, δεν έχουμε έναν εύκολο τρόπο να πάρουμε αυτή τη συμβολοσειρά και να την επεξεργαστούμε ως δομημένα δεδομένα. Εδώ μπαίνει στο παιχνίδι η BeautifulSoup. Η BeautifulSoup μας επιτρέπει να μετατρέψουμε το s.content σε δομημένα δεδομένα που μπορούμε στη συνέχεια να αναλύσουμε. Για να το κάνουμε αυτό, πρέπει πρώτα να εισάγουμε την BeautifulSoup. Σε αντίθεση με τις περισσότερες βιβλιοθήκες, η BeautifulSoup εγκαθίσταται ως bs4 (BeautifulSoup4). Εξαιτίας αυτού πρέπει να εισάγουμε την κλάση BeautifulSoup από το bs4. Η παρακάτω εντολή το κάνει αυτό για εμάς."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c92fba9-23df-420d-8997-c608aadf7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce2a95-353b-49ae-83ba-be15aa045912",
   "metadata": {},
   "source": [
    "Στη συνέχεια, πρέπει να δημιουργήσουμε ένα νέο soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f62efdb5-85e3-4eb6-bcfe-ecb7746e9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(s.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40df9c6-6507-47be-89d3-f2015670371d",
   "metadata": {},
   "source": [
    "Εάν δεν δούμε ένα σφάλμα, τότε σημαίνει ότι έχουμε δημιουργήσει επιτυχώς ένα soup object. Ας το εκτυπώσουμε για να δούμε πώς φαίνεται:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a028b365-4780-443c-8371-0db51c4bf72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>List of French monarchs - Wikipedia</title>\n",
      "<script>document.documentElement.className=\"client-js\";\n"
     ]
    }
   ],
   "source": [
    "print (str(soup)[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b939107-18d1-4b58-893d-b97082ec0dc9",
   "metadata": {},
   "source": [
    "Ενώ το soup object φαίνεται ακριβώς το ίδιο με το s.content, είναι εντελώς διαφορετικό. Διατηρεί τη δομή της HTML επειδή η BeautifulSoup την έχει αναλύσει για εμάς. Αυτό σημαίνει ότι μπορούμε να χρησιμοποιήσουμε ειδικές μεθόδους. Σε αυτήν την ενότητα του εγχειριδίου, θα χρησιμοποιήσουμε τις find και find_all.\n",
    "\n",
    "- find - αυτό θα μας επιτρέψει να βρούμε την πρώτη εμφάνιση ενός tag που χρησιμοποιείται και να πιάσουμε αυτό το tag και όλα τα ένθετα στοιχεία του.\n",
    "- find_all - αυτό θα επιστρέψει μια λίστα όλων των tags και των ένθετων στοιχείων τους που ευθυγραμμίζονται με αυτό το συγκεκριμένο tag.\n",
    "\n",
    "Ας ρίξουμε μια ματιά σε ένα βασικό παράδειγμα της μεθόδου find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc1c892-f5b6-4903-9437-7218162b6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "div = soup.find(\"div\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f53b0-c828-4a80-adee-d676d95e192b",
   "metadata": {},
   "source": [
    "Εδώ, πιάσαμε το πρώτο div tag στη σελίδα. Τα Div tags, ωστόσο, είναι αρκετά συνηθισμένα επειδή είναι ένα από τα βασικά δομικά στοιχεία της HTML. Ας ρίξουμε μια ματιά στο πόσα υπάρχουν σε ολόκληρη τη σελίδα. Μπορούμε να το κάνουμε αυτό με τη μέθοδο find_all και στη συνέχεια να μετρήσουμε το μέγεθος της λίστας με τη συνάρτηση len που συναντήσαμε στο κεφάλαιο 02_02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "132c4d25-982a-4330-b68e-c6a2f5b5541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "all_divs = soup.find_all(\"div\")\n",
    "print (len(all_divs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573814e-330a-4cb3-9375-277ffd5729bc",
   "metadata": {},
   "source": [
    "Έτσι, αν θέλουμε να πιάσουμε ένα συγκεκριμένο div μόνο με τις find και find_all, θα έπρεπε να μετρήσουμε όλα τα div tags και να βρούμε το σωστό index και να το πιάσουμε. Αυτό δεν θα λειτουργούσε σε κλίμακα επειδή αυτό θα ποικίλλει από σελίδα σε σελίδα, ακόμη και αν η δομή δεδομένων HTML ήταν παρόμοια σε όλες τις σελίδες σε έναν ιστότοπο. Χρειαζόμαστε μια καλύτερη λύση. Εδώ μπαίνει το δεύτερο προαιρετικό όρισμά μας. Η συνάρτηση find μπορεί επίσης να πάρει ένα λεξικό που μας επιτρέπει να περάσουμε κάποια συγκεκριμενοποίηση στην ανάλυσή μας του soup object.\n",
    "\n",
    "Ας πούμε ότι θέλω να πιάσω το κύριο σώμα του άρθρου της Wikipedia. Εάν επιθεωρήσω τη σελίδα, θα παρατηρήσω ότι ένα συγκεκριμένο div tag περιέχει όλα τα δεδομένα που αντιστοιχούν στο σώμα του άρθρου της Wikipedia. Αυτό το div tag έχει ένα ειδικό μοναδικό id attribute. Το όνομα αυτού του id attribute είναι \"mw-content-text\". Αυτό σημαίνει ότι μπορώ να περάσω ως δεύτερο όρισμα ένα λεξικό όπου το id είναι το κλειδί και το αντίστοιχο όνομα id είναι η τιμή. Αυτό θα πει στην BeautifulSoup να βρει το πρώτο div tag που έχει ένα id attribute που ταιριάζει με το mw-content-text. Ας ρίξουμε μια ματιά σε αυτό στον κώδικα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be6740ee-dcd6-493b-8fc8-a74288c8cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = soup.find(\"div\", {\"id\": \"mw-content-text\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117fd17c-5bd0-48b6-8a38-ebf404f42474",
   "metadata": {},
   "source": [
    "Τώρα που πιάσαμε αυτό το τμήμα του σώματος του άρθρου, μπορούμε να το εκτυπώσουμε με τη μέθοδο text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6ea4be4-0ae0-4955-bae2-25cba020370c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This article is about French monarchs. For Frankish kings, see List of Frankish kings.\n",
      "\n",
      "\n",
      " Division of the Frankish Empire at the Treaty of Verdun in 843\n",
      "The monarchs of the Kingdom of France ruled from the establishment of the Kingdom of the West Franks in 843 until the fall of the Second French Empire in 1870, with several interruptions. Between the period from King Charles the Bald in 843 to King Louis XVI in 1792, France had 45 kings. Adding the 7 emperors and kings after the French Revolut\n"
     ]
    }
   ],
   "source": [
    "print (body.text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6be50e-f435-46e9-a634-fa9e3c913602",
   "metadata": {},
   "source": [
    "Αυτό είναι φανταστικό! Αλλά, τι θα γινόταν αν θέλαμε να πιάσουμε το κείμενο και να διατηρήσουμε τη δομή των παραγράφων. Μπορούμε να το κάνουμε αυτό αναζητώντας το soup object στο επίπεδο του body. Το body object που δημιουργήσαμε είναι ακόμα ένα soup object που διατηρεί όλα αυτά τα δεδομένα HTML, αλλά περιέχει μόνο τα δεδομένα για τα δεδομένα που βρίσκονται κάτω από αυτό το συγκεκριμένο div. Μπορούμε να χρησιμοποιήσουμε το find all τώρα για να πιάσουμε όλες τις παραγράφους από μέσα στο body. Μπορούμε να χρησιμοποιήσουμε το find_all στο body object για να βρούμε όλες τις παραγράφους έτσι:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76620d88-aab9-434a-ba09-5d812f8f5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = body.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549ca72-d77e-45f2-a843-1349379815e4",
   "metadata": {},
   "source": [
    "Μπορούμε τώρα να επαναλάβουμε τις παραγράφους. Ας το κάνουμε αυτό τώρα στις πρώτες πέντε παραγράφους και ας εκτυπώσουμε το κείμενο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b7267ca-4ab0-4acc-aadc-98e20ebd851b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "The monarchs of the Kingdom of France ruled from the establishment of the Kingdom of the West Franks in 843 until the fall of the Second French Empire in 1870, with several interruptions. Between the period from King Charles the Bald in 843 to King Louis XVI in 1792, France had 45 kings. Adding the 7 emperors and kings after the French Revolution, this comes to a total of 52 monarchs of France.\n",
      "\n",
      "In August 843 the Treaty of Verdun divided the Frankish realm into three kingdoms, one of which (Middle Francia) was short-lived; the other two evolved into France (West Francia) and, eventually, Germany (East Francia). By this time, the eastern and western parts of the land had already developed different languages and cultures.\n",
      "\n",
      "Initially, the kingdom was ruled primarily by two dynasties, the Carolingians and the Robertians, who alternated rule from 843 until 987, when Hugh Capet, the progenitor of the Capetian dynasty, took the throne.  The kings use the title \"King of the Franks\" until the late twelfth century; the first to adopt the title of \"King of France\" was Philip II (r. 1180–1223).  The Capetians ruled continuously from 987 to 1792 and again from 1814 to 1848. The branches of the dynasty which ruled after 1328, however, are generally given the specific branch names of Valois (until 1589), Bourbon (from 1589 until 1792 and from 1814 until 1830), and the Orléans (from 1830 until 1848).\n"
     ]
    }
   ],
   "source": [
    "for paragraph in paragraphs[:5]:\n",
    "    print (paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51b335-c585-4235-9b82-0e9d6587e7e7",
   "metadata": {},
   "source": [
    "Viola! Τώρα έχετε επίσημα κάνει webscraping στην πρώτη σας σελίδα στην Python και πιάσατε κάποια σχετικά δεδομένα. Το scraping δεδομένων από τον ιστό δεν είναι ποτέ μια εργασία αντιγραφής και επικόλλησης επειδή κάθε ιστότοπος δομεί την HTML του λίγο διαφορετικά. Παρόλα αυτά, οι μηχανισμοί είναι οι ίδιοι. Οι βασικές μέθοδοι που μάθατε σε αυτό το κεφάλαιο θα πρέπει να σας επιτρέψουν να κάνετε scraping στην πλειοψηφία των στατικών ιστότοπων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c2f29-2b32-4598-9ae6-94bfada258d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}